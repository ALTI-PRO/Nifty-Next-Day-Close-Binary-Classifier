{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project For QI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries and classes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import talib as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting Date Range and Ticker\n",
    "start_date = '2018-1-1' #YYY-MM-DD\n",
    "end_date = '2020-12-31'\n",
    "ticker = 'HDFCBANK.NS'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading the data from yahoo finance\n",
    "df = yf.download(\"{}\".format(ticker), start=\"{}\".format(start_date), end=\"{}\".format(end_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the downloaded data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for outliers\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for Null values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the close price\n",
    "df['Adj Close'].plot(label='Closing Price')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a copy of data\n",
    "features = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the copy\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating functions for all the indicators\n",
    "\n",
    "def SMA (data, period=21, column = 'Adj Close'):\n",
    "    \n",
    "#    data ['SMA'] = data[column].rolling(window=period).mean()\n",
    "    return data[column].rolling(window=period).mean()\n",
    "\n",
    "\n",
    "def Pct_change (data, column = 'Adj Close'):\n",
    "    \n",
    "    data ['pct_change'] = (data[column].pct_change())*100\n",
    "    return (data[column].pct_change())*100\n",
    "\n",
    "\n",
    "#Instead of using a standard technical indicator, I have used 14 period rolling standard deviation of returns as a volatility indicator\n",
    "def Volatility (data, period = 14, column = 'pct_change'):\n",
    "    \n",
    "    data['Volatility'] = data[column].rolling(window=period).std()\n",
    "    return data[column].rolling(window=period).std()\n",
    "    \n",
    "\n",
    "def Volume_SMA(data, period=10, column = 'Volume'):\n",
    "\n",
    "    data['Volume_SMA'] = data[column].rolling(window=period).mean().round(2)\n",
    "    return data[column].rolling(window=period).mean().round(2)\n",
    "\n",
    "\n",
    "def RSI (data, period = 14, column = 'Adj Close'):\n",
    "    \"\"\"\n",
    "    This function calculates the RSI indicator\n",
    "  \n",
    "       Input : \n",
    "       first arg = dataframe\n",
    "       second arg = RSI period\n",
    "       third arg = column name on which RSI is to be calculated\n",
    "       \n",
    "       Output : \n",
    "       Returns RSI values and also creates an RSI column in the dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    x = features['Adj Close'].diff(1)\n",
    "    x = x.dropna()\n",
    "    rs_up = x.copy()\n",
    "    rs_down = x.copy()\n",
    "    rs_up[rs_up < 0] = 0\n",
    "    rs_down[rs_down > 0] = 0\n",
    "    data['rs_up'] = rs_up\n",
    "    data['rs_down'] = rs_down\n",
    "    pav = SMA(data, period, column = 'rs_up')\n",
    "    nav = abs (SMA(data, period, column = 'rs_down'))\n",
    "    RS = pav/nav\n",
    "    RSI = 100.0 - (100.0 / (1.0 + RS)) \n",
    "    \n",
    "    data ['RSI'] = RSI\n",
    "    return data      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating all the indicators\n",
    "RSI(features)\n",
    "Pct_change(features)\n",
    "Volatility(features)\n",
    "Volume_SMA(features)\n",
    "#For MOM indicator we are using talib instead of writing and using a function\n",
    "features['ROC'] = ta.ROC(features['Adj Close'], timeperiod = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the features (indicators)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the dependent variable. If next day close was up, 1 or -1\n",
    "features['Dependent_Variable'] = np.where(features['pct_change'].shift(-1) > 0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the features\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing all the rows with NaN values\n",
    "features = features.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the features\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new features dataframe containing only indicators and the independent variable\n",
    "features_new = features.filter(['ROC','RSI', 'Volatility', 'Volume_SMA', 'Dependent_Variable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the new dataframe\n",
    "features_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_new.iloc[:, :-1].values #Independent Variables\n",
    "y = features_new.iloc[:, -1].values   #Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##                                       Reason for Selecting XB Boost\n",
    "\n",
    "Five different models were traine on the same data. The performance was compared based on weighted average f1 score. They have been listed below in descending order of their performance. XG boost outperformed all these models\n",
    "\n",
    "XG Boost: 52, Random Forest - 0.50, KNN - 0.51, Decision Tree - 0.47, Naive Baise - 0.41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "import sklearn\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing f1 score and accuracy report\n",
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can we improving the performance?\n",
    "\n",
    "1)  and Feature Engineering \n",
    "To boost the models performance, some proprietory indicators can be created based on research. \n",
    "\n",
    "2) Feature selection\n",
    "Including more indicators of different classes might help imporove the performance of the model. For eg. including the data from the derivatives market such as OI can help the model with market sentiment. We can also include data from social media, macroeconomic indicators, bond yields etc.\n",
    "\n",
    "3) Optimizing Indicator Parameters\n",
    "Short term and long term trends can be defined with slower and faster parameters for the indicators.\n",
    "\n",
    "4) Tuning Hyper Parameters of the Mode  \n",
    "There are many parameters of the model which the models do not learn during training. Thus tuning the hyperparameters might give a performance boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Baise\n",
    "#Training\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "#Prediction\n",
    "y_pred = classifier.predict(X_test)\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "#Training\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "#Prediction\n",
    "y_pred = classifier.predict(X_test)\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "#Training\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "#Prediction\n",
    "y_pred = classifier.predict(X_test)\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "#Training\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train, y_train)\n",
    "#Prediction\n",
    "y_pred = classifier.predict(X_test)\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "#Training\n",
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "#Prediction\n",
    "y_pred = classifier.predict(X_test)\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
